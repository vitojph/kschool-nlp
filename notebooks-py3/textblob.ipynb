{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `textblob`: otro módulo para tareas de PLN (`NLTK` + `pattern`)\n",
    "\n",
    "[textblob](http://textblob.readthedocs.org/) es una librería de procesamiento del texto para Python que permite realizar tareas de Procesamiento del Lenguaje Natural como análisis morfológico, extracción de entidades, análisis de opinión, traducción automática, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Está construida sobre otras dos librerías muy famosas de Python: [NLTK](http://www.nltk.org/) y [pattern](http://www.clips.ua.ac.be/pages/pattern-en). La principal ventaja de [textblob](http://textblob.readthedocs.org/) es que permite combinar el uso de las dos herramientas anteriores en un interfaz más simple.\n",
    "\n",
    "Vamos a apoyarnos en [este tutorial](http://textblob.readthedocs.org/en/dev/quickstart.html) para aprender a utilizar algunas de sus funcionalidades más llamativas. \n",
    "\n",
    "Lo primero es importar el objeto `TextBlob` que nos permite acceder a todas las herramentas que incluye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear nuestro primer ejemplo de *textblob* a través del objeto `TextBlob`. Piensa en estos *textblobs* como una especie de cadenas de texto de Python, analaizadas y enriquecidas con algunas características extra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texto = '''In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n",
    "and San Francisco counties make an important point about the lightly regulated sharing economy. The consumers who \n",
    "participate deserve a  very clear picture of the risks they're taking'''\n",
    "t = TextBlob(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n",
      "and San Francisco counties make an important point about the lightly regulated sharing economy.\"), Sentence(\"The consumers who \n",
      "participate deserve a  very clear picture of the risks they're taking\")]\n"
     ]
    }
   ],
   "source": [
    "print(t.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 2 oraciones.\n",
      "\n",
      "In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n",
      "and San Francisco counties make an important point about the lightly regulated sharing economy.\n",
      "---------------------------------------------------------------------------\n",
      "The consumers who \n",
      "participate deserve a  very clear picture of the risks they're taking\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Tenemos', len(t.sentences), 'oraciones.\\n')\n",
    "\n",
    "for sentence in t.sentences:\n",
    "    print(sentence)\n",
    "    print('-' * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesando oraciones, palabras y entidades\n",
    "\n",
    "Podemos segmentar en oraciones y en palabras nuestra texto de ejemplo simplemente accediendo a las propiedades `.sentences` y `.words`. Imprimimos por pantalla: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n",
      "and San Francisco counties make an important point about the lightly regulated sharing economy.\n",
      "---------------------------------------------------------------------------\n",
      "The consumers who \n",
      "participate deserve a  very clear picture of the risks they're taking\n",
      "---------------------------------------------------------------------------\n",
      "['In', 'new', 'lawsuits', 'brought', 'against', 'the', 'ride-sharing', 'companies', 'Uber', 'and', 'Lyft', 'the', 'top', 'prosecutors', 'in', 'Los', 'Angeles', 'and', 'San', 'Francisco', 'counties', 'make', 'an', 'important', 'point', 'about', 'the', 'lightly', 'regulated', 'sharing', 'economy', 'The', 'consumers', 'who', 'participate', 'deserve', 'a', 'very', 'clear', 'picture', 'of', 'the', 'risks', 'they', \"'re\", 'taking']\n",
      "['In', 'new', 'lawsuits', 'brought', 'against', 'the', 'ride-sharing', 'companies', 'Uber', 'and', 'Lyft,', 'the', 'top', 'prosecutors', 'in', 'Los', 'Angeles', 'and', 'San', 'Francisco', 'counties', 'make', 'an', 'important', 'point', 'about', 'the', 'lightly', 'regulated', 'sharing', 'economy.', 'The', 'consumers', 'who', 'participate', 'deserve', 'a', 'very', 'clear', 'picture', 'of', 'the', 'risks', \"they're\", 'taking']\n"
     ]
    }
   ],
   "source": [
    "# imprimimos las oraciones\n",
    "for sentence in t.sentences:\n",
    "    print(sentence)\n",
    "    print('-' * 75)\n",
    "    \n",
    "# y las palabras    \n",
    "print(t.words)\n",
    "print(texto.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propiedad `.noun_phrases` nos permite acceder a la lista de entidades (en realidad, son sintagmas nominales) incluídos en nuestro *textblob*. Así es como funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el texto de ejemplo contiene 8 entidades\n",
      "- new lawsuits\n",
      "- uber\n",
      "- lyft\n",
      "- top prosecutors\n",
      "- los angeles\n",
      "- san francisco\n",
      "- important point\n",
      "- clear picture\n"
     ]
    }
   ],
   "source": [
    "print(\"el texto de ejemplo contiene\", len(t.noun_phrases), \"entidades\")\n",
    "for element in t.noun_phrases:\n",
    "    print(\"-\", element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In In Ins\n",
      "new new news\n",
      "lawsuit lawsuits lawsuit\n",
      "brought brought broughts\n",
      "against against againsts\n",
      "the the thes\n",
      "ride-sharing ride-sharing ride-sharings\n",
      "company companies company\n",
      "Uber Uber Ubers\n",
      "and and ands\n",
      "Lyft Lyft Lyfts\n",
      "the the thes\n",
      "top top tops\n",
      "prosecutor prosecutors prosecutor\n",
      "in in ins\n",
      "Los Los Lo\n",
      "Angeles Angeles Angele\n",
      "and and ands\n",
      "San San Sans\n",
      "Francisco Francisco Franciscoes\n",
      "county counties county\n",
      "make make makes\n",
      "an an some\n",
      "important important importants\n",
      "point point points\n",
      "about about abouts\n",
      "the the thes\n",
      "lightly lightly lightlies\n",
      "regulated regulated regulateds\n",
      "sharing sharing sharings\n",
      "economy economy economies\n",
      "The The Thes\n",
      "consumer consumers consumer\n",
      "who who whoes\n",
      "participate participate participates\n",
      "deserve deserve deserves\n",
      "a a some\n",
      "very very veries\n",
      "clear clear clears\n",
      "picture picture pictures\n",
      "of of ofs\n",
      "the the thes\n",
      "risk risks risk\n",
      "they they they\n",
      "'re 're 'res\n",
      "taking taking takings\n"
     ]
    }
   ],
   "source": [
    "# jugando con lemas, singulares y plurales \n",
    "for word in t.words:\n",
    "    if word.endswith(\"s\"):\n",
    "        print(word.lemmatize(), word, word.singularize())\n",
    "    else:\n",
    "        print(word.lemmatize(), word, word.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In In\n",
      "new new\n",
      "lawsuits --> lawsuit\n",
      "brought brought\n",
      "against against\n",
      "the the\n",
      "ride-sharing ride-sharing\n",
      "companies --> company\n",
      "Uber Uber\n",
      "and and\n",
      "Lyft Lyft\n",
      "the the\n",
      "top top\n",
      "prosecutors --> prosecutor\n",
      "in in\n",
      "Los Los\n",
      "Angeles Angeles\n",
      "and and\n",
      "San San\n",
      "Francisco Francisco\n",
      "counties --> county\n",
      "make make\n",
      "an an\n",
      "important important\n",
      "point --> points\n",
      "about about\n",
      "the the\n",
      "lightly lightly\n",
      "regulated regulated\n",
      "sharing sharing\n",
      "economy --> economies\n",
      "The The\n",
      "consumers --> consumer\n",
      "who who\n",
      "participate participate\n",
      "deserve deserve\n",
      "a a\n",
      "very very\n",
      "clear clear\n",
      "picture --> pictures\n",
      "of of\n",
      "the the\n",
      "risks --> risk\n",
      "they they\n",
      "'re 're\n",
      "taking taking\n"
     ]
    }
   ],
   "source": [
    "# ¿cómo podemos hacer la lematización más inteligente?\n",
    "for item in t.tags:\n",
    "    if item[1] == 'NN':\n",
    "        print(item[0], '-->', item[0].pluralize())\n",
    "    elif item[1] == 'NNS':\n",
    "        print(item[0], '-->', item[0].singularize())\n",
    "    else:\n",
    "        print(item[0], item[0].lemmatize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis sintático\n",
    "\n",
    "Aunque podemos utilizar otros analizadores, por defecto el método `.parse()` invoca al analizador morfosintáctico del módulo  `pattern.en` que ya conoces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In/IN/B-PP/B-PNP new/JJ/B-NP/I-PNP lawsuits/NNS/I-NP/I-PNP brought/VBN/B-VP/I-PNP against/IN/B-PP/B-PNP the/DT/B-NP/I-PNP ride-sharing/JJ/I-NP/I-PNP companies/NNS/I-NP/I-PNP Uber/NNP/I-NP/I-PNP and/CC/O/O Lyft/NNP/B-NP/O ,/,/O/O the/DT/B-NP/O top/JJ/I-NP/O prosecutors/NNS/I-NP/O in/IN/B-PP/B-PNP Los/NNP/B-NP/I-PNP Angeles/NNP/I-NP/I-PNP and/CC/I-NP/I-PNP San/NNP/I-NP/I-PNP Francisco/NNP/I-NP/I-PNP counties/NNS/I-NP/I-PNP make/VB/B-VP/O an/DT/B-NP/O important/JJ/I-NP/O point/NN/I-NP/O about/IN/B-PP/O the/DT/O/O lightly/RB/B-VP/O regulated/VBN/I-VP/O sharing/VBG/I-VP/O economy/NN/B-NP/O ././O/O\n",
      "The/DT/B-NP/O consumers/NNS/I-NP/O who/WP/O/O participate/VB/B-VP/O deserve/VBP/I-VP/O a/DT/B-NP/O very/RB/I-NP/O clear/JJ/I-NP/O picture/NN/I-NP/O of/IN/B-PP/B-PNP the/DT/B-NP/I-PNP risks/NNS/I-NP/I-PNP they/PRP/I-NP/I-PNP '/POS/O/O re/NN/B-NP/O taking/VBG/B-VP/O\n"
     ]
    }
   ],
   "source": [
    "# análisis sintáctico\n",
    "print(t.parse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traducción automática\n",
    "\n",
    "\n",
    "A partir de cualquier texto procesado con `TextBlob`, podemos acceder a un traductor automático de bastante calidad con el método `.translate`. Fíjate en cómo lo usamos. Es obligatorio indicar la lengua de destinto. La lengua de origen, se puede predecir a partir del texto de entrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China lunar exploration project, also known as Chang'e project, is the first lunar exploration project launched in China, officially launched on March 1, 2003\n",
      "Programa de Exploración Lunar chino, también conocido como proyecto Chang E es comenzar el primer programa de exploración lunar de China, el 1 de marzo de 2003 lanzó oficialmente\n",
      "--------------\n",
      "Το δημόσιο χρέος έχει θέσει νέο ρεκόρ στην Ισπανία κατά το τρίτο τρίμηνο\n",
      "Госдолг установил новые рекорды в Испании в третьем квартале\n",
      "zor publikoa Espainian erregistro berriak ezarri du hirugarren hiruhilekoan\n",
      "Julkinen velka on asettanut uusia ennätyksiä Espanjassa kolmannella neljänneksellä\n",
      "La dette publique a établi de nouveaux records en Espagne au troisième trimestre\n",
      "De overheidsschuld heeft nieuwe records in Spanje in het derde kwartaal\n",
      "A débeda pública comezou novas marcas en España no terceiro trimestre\n",
      "El deute públic ha marcat nous rècords a Espanya en el tercer trimestre\n",
      "公共债务在第三季度创下的西班牙新纪录\n",
      "Debitum palam novum records in Hispaniam profectus est, in tertia quartam\n",
      "Veřejný dluh vytváří nové rekordy ve Španělsku se ve třetím čtvrtletí\n",
      "--------------\n",
      "I went to Milan and enjoyed a brothel.\n",
      "Fui a Milán y me gustó mucho un burdel.\n"
     ]
    }
   ],
   "source": [
    "# de chino a inglés y español \n",
    "oracion_zh = \"中国探月工程 亦稱嫦娥工程，是中国启动的第一个探月工程，于2003年3月1日正式启动\"\n",
    "t_zh = TextBlob(oracion_zh)\n",
    "print(t_zh.translate(from_lang=\"zh-CN\", to=\"en\"))\n",
    "print(t_zh.translate(from_lang=\"zh-CN\", to=\"es\"))\n",
    "\n",
    "print(\"--------------\")\n",
    "\n",
    "t_es = TextBlob(u\"La deuda pública ha marcado nuevos récords en España en el tercer trimestre\")\n",
    "print(t_es.translate(to=\"el\"))\n",
    "print(t_es.translate(to=\"ru\"))\n",
    "print(t_es.translate(to=\"eu\"))\n",
    "print(t_es.translate(to=\"fi\"))\n",
    "print(t_es.translate(to=\"fr\"))\n",
    "print(t_es.translate(to=\"nl\"))\n",
    "print(t_es.translate(to=\"gl\"))\n",
    "print(t_es.translate(to=\"ca\"))\n",
    "print(t_es.translate(to=\"zh\"))\n",
    "print(t_es.translate(to=\"la\"))\n",
    "print(t_es.translate(to=\"cs\"))\n",
    "\n",
    "# con el slang no funciona tan bien\n",
    "print(\"--------------\")\n",
    "t_ita = TextBlob(u\"Sono andato a Milano e mi sono divertito un bordello.\")\n",
    "print(t_ita.translate(to=\"en\"))\n",
    "print(t_ita.translate(to=\"es\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet\n",
    "\n",
    "`textblob`, más concretamente, cualquier objeto de la clase `Word`, nos permite acceder a la información de WordNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'), Synset('cable_car.n.01')]\n",
      "[Synset('chop.v.05'), Synset('hack.v.02'), Synset('hack.v.03'), Synset('hack.v.04'), Synset('hack.v.05'), Synset('hack.v.06'), Synset('hack.v.07'), Synset('hack.v.08')]\n",
      "['a motor vehicle with four wheels; usually propelled by an internal combustion engine', 'a wheeled vehicle adapted to the rails of railroad', 'the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant', 'where passengers ride up and down', 'a conveyance for passengers or freight on a cable railway']\n",
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('container.n.01'), Synset('wheeled_vehicle.n.01'), Synset('self-propelled_vehicle.n.01'), Synset('motor_vehicle.n.01'), Synset('car.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('conveyance.n.03'), Synset('vehicle.n.01'), Synset('wheeled_vehicle.n.01'), Synset('self-propelled_vehicle.n.01'), Synset('motor_vehicle.n.01'), Synset('car.n.01')]]\n",
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('container.n.01'), Synset('wheeled_vehicle.n.01'), Synset('car.n.02')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('conveyance.n.03'), Synset('vehicle.n.01'), Synset('wheeled_vehicle.n.01'), Synset('car.n.02')]]\n",
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('structure.n.01'), Synset('area.n.05'), Synset('room.n.01'), Synset('compartment.n.02'), Synset('car.n.03')]]\n",
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('structure.n.01'), Synset('area.n.05'), Synset('room.n.01'), Synset('compartment.n.02'), Synset('car.n.04')]]\n",
      "[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('structure.n.01'), Synset('area.n.05'), Synset('room.n.01'), Synset('compartment.n.02'), Synset('cable_car.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "# WordNet\n",
    "from textblob import Word\n",
    "from textblob.wordnet import VERB\n",
    "\n",
    "# ¿cuántos synsets tiene \"car\"\n",
    "word = Word(\"car\")\n",
    "print(word.synsets)\n",
    "\n",
    "# dame los synsets de la palabra \"hack\" como verbo\n",
    "print(Word(\"hack\").get_synsets(pos=VERB))\n",
    "\n",
    "# imprime la lista de definiciones de \"car\"\n",
    "print(Word(\"car\").definitions)\n",
    "\n",
    "# recorre la jerarquía de hiperónimos\n",
    "for s in word.synsets:\n",
    "    print(s.hypernym_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.5387784090909091, subjectivity=0.6011363636363636)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "0.5387784090909091\n",
      "Hey, esto es una opinion\n"
     ]
    }
   ],
   "source": [
    "# análisis de opinión\n",
    "opinion1 = TextBlob(\"This new restaurant is great. I had so much fun!! :-P\")\n",
    "print(opinion1.sentiment)\n",
    "\n",
    "opinion2 = TextBlob(\"Google News to close in Spain.\")\n",
    "print(opinion2.sentiment)\n",
    "\n",
    "# subjetividad 0:1\n",
    "# polaridad -1:1\n",
    "\n",
    "print(opinion1.sentiment.polarity)\n",
    "\n",
    "if opinion1.sentiment.subjectivity > 0.5:\n",
    "    print(\"Hey, esto es una opinion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.5, subjectivity=0.6)\n",
      "Sentiment(polarity=0.5, subjectivity=0.6)\n",
      "Sentiment(polarity=0.5, subjectivity=0.8)\n",
      "Sentiment(polarity=-0.4625, subjectivity=0.8)\n"
     ]
    }
   ],
   "source": [
    "t = TextBlob(\"I like this restaurant\")\n",
    "print(t.sentiment)\n",
    "\n",
    "t = TextBlob(\"I love this restaurant\")\n",
    "print(t.sentiment)\n",
    "\n",
    "t = TextBlob(\"I fucking love this restaurant \")\n",
    "print(t.sentiment)\n",
    "\n",
    "t = TextBlob(\"I fucking love this restaurant :-) \")\n",
    "print(t.sentiment)\n",
    "\n",
    "t = TextBlob(\"I love this FUCKING restaurant :-( Grrr!! \")\n",
    "print(t.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otras curiosidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n",
      "In name in On!\n",
      "Boy dont cry\n",
      "psychological position achifmen commitment\n"
     ]
    }
   ],
   "source": [
    "#  corrección ortográfica\n",
    "b1 = TextBlob(\"I havv goood speling!\")\n",
    "print(b1.correct())\n",
    "\n",
    "b2 = TextBlob(\"Miy naem iz Jonh!\")\n",
    "print(b2.correct())\n",
    "\n",
    "b3 = TextBlob(\"Boyz dont cri\")\n",
    "print(b3.correct())\n",
    "\n",
    "b4 = TextBlob(\"psicological posesion achifmen comitment\")\n",
    "print(b4.correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasta el infinito, y más allá\n",
    "\n",
    "En este breve resumen solo consideramos las posibilidades que ofrece `TextBlob` por defecto. Pero si necesitas personalizar las herramientas, echa un vistazo a [la documentación avanzada](http://textblob.readthedocs.org/en/dev/advanced_usage.html#advanced). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

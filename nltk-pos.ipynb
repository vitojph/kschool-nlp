{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen NLTK: Etiquetado morfológico (*part-of-speech tagging*)\n",
    "\n",
    "Este resumen se corresponde con el capítulo 5 del NLTK Book [Categorizing and Tagging Words](http://www.nltk.org/book/ch05.html). La lectura del capítulo es muy recomendable.\n",
    "\n",
    "\n",
    "## Etiquetado morfológico con NLTK\n",
    "\n",
    "NLTK propociona varias herramientas para poder crear fácilmente etiquetadores morfológicos (*part-of-speech taggers*). Veamos algunos ejemplos.\n",
    "\n",
    "Para empezar, necesitamos importar el módulo `nltk` que nos da acceso a todas las funcionalidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer ejemplo, podemos utilizar la función `nltk.pos_tag` para etiquetar morfológicamente una oración en inglés, siempre que la especifiquemos como una lista de palabras o tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('the', 'DT'), ('lost', 'JJ'), ('dog', 'NN'), ('I', 'PRP'), ('found', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('park', 'NN')]\n",
      "[('The', 'DT'), ('progress', 'NN'), ('of', 'IN'), ('the', 'DT'), ('humankind', 'NN'), ('as', 'IN'), ('I', 'PRP'), ('progress', 'VBP')]\n"
     ]
    }
   ],
   "source": [
    "oracion1 = \"This is the lost dog I found at the park\".split()\n",
    "oracion2 = \"The progress of the humankind as I progress\".split()\n",
    "print(nltk.pos_tag(oracion1))\n",
    "print(nltk.pos_tag(oracion2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El etiquetador funciona bastante bien aunque comete errores, obviamente. Si probamos con la famosa frase de Chomksy detectamos palabras mal etiquetadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Green', 'JJ'), ('colorless', 'NN'), ('ideas', 'NNS'), ('sleep', 'VBP'), ('furiously', 'RB')]\n",
      "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Prince', 'NNP')]\n",
      "[('He', 'PRP'), ('was', 'VBD'), ('born', 'VBN'), ('during', 'IN'), ('the', 'DT'), ('summer', 'NN'), ('of', 'IN'), ('1988', 'CD')]\n",
      "[(\"She's\", 'NNP'), (\"Tony's\", 'NNP'), ('sister', 'NN')]\n",
      "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Xrtwewvdk', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "oracion3 = \"Green colorless ideas sleep furiously\".split()\n",
    "\n",
    "print(nltk.pos_tag(oracion3))\n",
    "\n",
    "print(nltk.pos_tag([\"My\", \"name\", \"is\", \"Prince\"]))\n",
    "\n",
    "print(nltk.pos_tag('He was born during the summer of 1988'.split()))\n",
    "\n",
    "print(nltk.pos_tag(\"She's Tony's sister\".split()))\n",
    "\n",
    "print(nltk.pos_tag('''My name is Xrtwewvdk'''.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo funciona este etiquetador? `nltk.pos_tag` es un etiquetador morfológico basado en aprendizaje automático. A partir de miles de ejemplos de oraciones etiquetadas manualmente, el sistema *ha aprendido*, calculando frecuencias y generalizando cuál es la categoría gramatical más probable para cada token. \n",
    "\n",
    "Como sabes, desde NLTK podemos acceder a corpus que ya están etiquetados. Vamos a utilizar alguno de los que ya conoces, el corpus de Brown, para entrenar nuestros propios etiquetadores.\n",
    "\n",
    "Para ello importamos el corpus de Brown y almacenamos en un par de variables las noticias de este corpus en su versión etiquetada morfológicamente y sin etiquetar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_sents = brown.sents(categories=\"news\")\n",
    "brown_tagged_sents = brown.tagged_sents(categories=\"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comparar ambas versiones, podemos imprimir la primera oración de este corpus en su versión sin etiquetas (fíjate que se trata de una lista de tokens, sin más) y en su versión etiquetada (se trata de una lista de tuplas donde el primer elemento es el token y el segundo es la etiqueta morfológica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# imprimimos la primera oración de las noticias de Brown\n",
    "print(brown_sents[0]) # sin anotar\n",
    "print(brown_tagged_sents[0]) # etiquetada morfológicamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetado morfológico automático\n",
    "\n",
    "### Etiquetador por defecto\n",
    "\n",
    "NLTK nos da acceso a tipos de etiquetadores morfológicos. Veamos cómo utilizar algunos de ellos.\n",
    "\n",
    "A la hora de enfrentarnos al etiquetado morfológico de un texto, podemos adoptar una estrategia sencilla consistente en etiquetar por defecto todas las palabras con la misma categoría gramatical. Con NLTK podemos utilizar un `DefaultTagger` que etiquete todos los tokens como sustantivo. Las categoría **sustantivo singular** (`NN` en el esquema de etiquetas de Treebank) suele ser la más frecuente. Veamos qué tal funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'NN'), ('is', 'NN'), ('the', 'NN'), ('lost', 'NN'), ('dog', 'NN'), ('I', 'NN'), ('found', 'NN'), ('at', 'NN'), ('the', 'NN'), ('park', 'NN')]\n",
      "[('The', 'NN'), ('progress', 'NN'), ('of', 'NN'), ('the', 'NN'), ('humankind', 'NN'), ('as', 'NN'), ('I', 'NN'), ('progress', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "defaultTagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "print(defaultTagger.tag(oracion1))\n",
    "print(defaultTagger.tag(oracion2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente no funciona bien, pero ojo, en el ejemplo anterior con `oracion1` hemos etiquetado correctamente 2 de 10 tokens. Si lo evaluamos con un corpus más grande, como el conjunto de oraciones de Brown que ya tenemos, obtenemos una precisión superior al 13%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13089484257215028"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultTagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el método `.evaluate` que podemos ejecutar con cualquier etiquetador si especificamos como argumento una colección de referencia que ya esté etiquetada, nos devuelve un número: la **precisión**. Esta precisión se calcula como el porcentaje de tokens correctamente etiquetados por el *tagger*, teniendo en cuenta el corpus especificado como referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente, los resultados son malos. Probemos con otras opciones más sofisticadas.\n",
    "\n",
    "### Etiquetador basado en Expresiones Regulares\n",
    "\n",
    "Las expresiones regulares consisten en un lenguaje formal que nos permite especificar cadenas de texto. Ya las hemos utilizado en ocasiones anteriores. Pues bien, ahora podemos probar a definir distintas categorías morfológicas a partir de patrones, al menos para fenómenos morfológicos regulares.\n",
    "\n",
    "A continuación definimos la variable `patrones` como una lista de tuplas, cuyo primer elemento se corresponde con la expresion regular que queremos capturar y el segundo elemento como la categoría gramatical. Y a partir de estas expresiones regulares creamos un `RegexpTagger`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patrones = [\n",
    "    (r'[Aa]m$', 'VBP'),               # irregular forms of 'to be' \n",
    "    (r'[Aa]re$', 'VBP'),              #  \n",
    "    (r'[Ii]s$', 'VBZ'),               #  \n",
    "    (r'[Ww]as$', 'VBD'),              #  \n",
    "    (r'[Ww]ere$', 'VBD'),             #  \n",
    "    (r'[Bb]een$', 'VBN'),             #  \n",
    "    (r'[Hh]ave$', 'VBP'),             # irregular forms of 'to be' \n",
    "    (r'[Hh]as$', 'VBZ'),              #  \n",
    "    (r'[Hh]ad$', 'VBD'),              #\n",
    "    (r'^I$', 'PRP'),                  # personal pronouns\n",
    "    (r'[Yy]ou$', 'PRP'),              # \n",
    "    (r'[Hh]e$', 'PRP'),               # \n",
    "    (r'[Ss]he$', 'PRP'),              # \n",
    "    (r'[Ii]t$', 'PRP'),               # \n",
    "    (r'[Tt]hey$', 'PRP'),             # \n",
    "    (r'[Aa]n?$', 'AT'),               # \n",
    "    (r'[Tt]he$', 'AT'),               # \n",
    "    (r'[Ww]h.+$', 'WP'),              # wh- pronoun\n",
    "    (r'.*ing$', 'VBG'),               # gerunds\n",
    "    (r'.*ed$', 'VBD'),                # simple past\n",
    "    (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "    (r'[Cc]an(not|n\\'t)?$', 'MD'),    # modals\n",
    "    (r'[Mm]ight$', 'MD'),             # \n",
    "    (r'[Mm]ay$', 'MD'),               # \n",
    "    (r'.+ould$', 'MD'),               # modals: could, should, would\n",
    "    (r'.*ly$', 'RB'),                 # adverbs\n",
    "    (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                 # plural nouns\n",
    "    (r'-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n",
    "    (r'^to$', 'TO'),                  # to \n",
    "    (r'^in$', 'IN'),                  # in prep\n",
    "    (r'^[A-Z]+([a-z])*$', 'NNP'),     # proper nouns \n",
    "    (r'.*', 'NN')                     # nouns (default)\n",
    "]\n",
    "\n",
    "regexTagger = nltk.RegexpTagger(patrones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('was', 'VBD'), ('taking', 'VBG'), ('a', 'AT'), ('sunbath', 'NN'), ('in', 'IN'), ('Alpedrete', 'NNP')]\n",
      "[('She', 'PRP'), ('would', 'MD'), ('have', 'VBP'), ('found', 'NN'), ('100', 'CD'), ('dollars', 'NNS'), ('in', 'IN'), ('the', 'AT'), ('bag', 'NN')]\n",
      "[('DSFdfdsfsd', 'NNP'), ('1852', 'CD'), ('to', 'TO'), ('dgdfgould', 'MD'), ('fXXXdg', 'NN'), ('in', 'IN'), ('XXXfdg', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(regexTagger.tag(\"I was taking a sunbath in Alpedrete\".split()))\n",
    "\n",
    "print(regexTagger.tag(\"She would have found 100 dollars in the bag\".split()))\n",
    "\n",
    "print(regexTagger.tag(\"DSFdfdsfsd 1852 to dgdfgould fXXXdg in XXXfdg\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando probamos a evaluarlo con un corpus de oraciones más grande, vemos que nuestra precisión sube por encima del 32%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3260636076138194"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexTagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetado basado en ngramas\n",
    "\n",
    "Antes hemos dicho que la función `nltk.pos_tag` tenía un etiquetador morfológico que funcionaba con información estadística. A continuación vamos a reproducir, a pequeña escala, el proceso de entrenamiento de un etiquetador morfológico basado en aprendizaje automático. \n",
    "\n",
    "En general, los sistemas de aprendizaje automático funcionan del siguiente modo:\n",
    "\n",
    "* Se etiqueta manualmente una colección de datos. Cuanto más grande y más representativa sea la colección, mejores datos podremos extraer.\n",
    "* El sistema de aprendizaje procesa la colección de entrenamiento y \"aprende\" a partir de los ejemplos observados. En el caso del etiquetado morfológico, el sistema calcula frecuencias y generaliza (de distintas maneras) cuáles son las categorías gramaticales más probables para cada palabra. \n",
    "* Una vez que el sistema ha sido entrenado, se evalúa su rendimiento sobre datos no observados.\n",
    "\n",
    "Nosotros tenemos un pequeño corpus de ejemplos etiquetados: las oraciones del corpus de Brown de la categoría \"noticias\". Lo primero que necesitamos hacer es separar nuestros corpus de entrenamiento y test. En este caso, vamos a reservar el primer 90% de las oraciones para el entrenamiento (serán los ejemplos observados a partir de los cuales nuestro etiquetador aprenderá) y vamos a dejar el 10% restante para comprobar qué tal funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4623\n",
      "4160.7\n"
     ]
    }
   ],
   "source": [
    "print(len(brown_tagged_sents))\n",
    "\n",
    "print((len(brown_tagged_sents) * 90) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n",
      "[('But', 'CC'), ('in', 'IN'), ('all', 'ABN'), ('its', 'PP$'), ('175', 'CD'), ('years', 'NNS'), (',', ','), ('not', '*'), ('a', 'AT'), ('single', 'AP'), ('Negro', 'NP'), ('student', 'NN'), ('has', 'HVZ'), ('entered', 'VBN'), ('its', 'PP$'), ('classrooms', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9) # asegúrate de que conviertes esto a entero \n",
    "corpusEntrenamiento = brown_tagged_sents[:size]\n",
    "corpusTest = brown_tagged_sents[size:]\n",
    "\n",
    "# como ves, estos corpus contienen oraciones diferentes\n",
    "print(corpusEntrenamiento[0])\n",
    "print(corpusTest[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a crear un etiquetador basado en unigramas (secuencias de una palabra o palabras sueltas) a través de la clase `nltk.UnigramTagger`, proporcionando nuestro `corpusEntrenamiento` para que aprenda. Una vez entrenado, vamos a evaluar su rendimiento sobre `corpusTest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125186883285159\n"
     ]
    }
   ],
   "source": [
    "unigramTagger = nltk.UnigramTagger(corpusEntrenamiento)\n",
    "print(unigramTagger.evaluate(corpusTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'BEZ'), ('the', 'AT'), ('lost', 'VBD'), ('dog', 'NN'), ('I', 'PPSS'), ('found', 'VBN'), ('at', 'IN'), ('the', 'AT'), ('park', 'NN')]\n",
      "[('The', 'AT'), ('progress', 'NN'), ('of', 'IN'), ('the', 'AT'), ('humankind', None), ('as', 'CS'), ('I', 'PPSS'), ('progress', 'NN')]\n",
      "[('Green', 'JJ-TL'), ('colorless', None), ('ideas', 'NNS'), ('sleep', None), ('furiously', None)]\n"
     ]
    }
   ],
   "source": [
    "# ¿qué tal se etiquetan nuestras oraciones de ejemplo?\n",
    "print(unigramTagger.tag(oracion1))\n",
    "print(unigramTagger.tag(oracion2))\n",
    "print(unigramTagger.tag(oracion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los etiquetadores basados en unigramas se construyen a partir del simple cálculo de una distribución de frecuencia para cada token (palabra) y asignan siempre la etiqueta morfológica más probable. En nuestro caso, esta estrategia funciona relativamente bien: el tagger supera el 81% de precisión. Sin embargo, esta aproximación presenta numerosos problemas a la hora de etiquetar palabras homógrafas (un mismo token funcionando con más de una categoría gramatical). Si probamos con nuestra `oracion2`, comprobamos que la segunda aparición de *progress* no es etiquetada correctamente.\n",
    "\n",
    "Intuitivamente, podemos pensar que sabríamos distinguir ambas categorías si tuviéramos en cuenta algo del contexto de aparición de las palabras: *progress* es un sustantivo cuando aparece después del artículo *the* y es verbo cuando aparece tras un pronombre personal como *I*. Si en lugar de calcular frecuencias de unigramas, extendiéramos los cálculos a secuencias de dos o tres palabras, podríamos tener mejores resultados. Y precisamente por eso vamos a calcular distribuciones de frecuencias condicionales: asignaremos a cada token la categoría gramatical más frecuente teniendo en cuenta la categoría gramatical de la(s) palabra(s) inmediatamente anterior(es). \n",
    "\n",
    "Creamos un par de etiquetadores basado en bigramas (secuencias de dos palabras) o trigramas (secuencias de tres palabras) a través de las clases `nltk.BigramTagger` y `nltk.TrigramTagger`. Y los probamos con nuestra `oracion2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigramTagger = nltk.BigramTagger(corpusEntrenamiento)\n",
    "\n",
    "trigramTagger = nltk.TrigramTagger(corpusEntrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('progress', None), ('of', None), ('the', None), ('humankind', None), ('as', None), ('I', None), ('progress', None)]\n",
      "[('The', 'AT'), ('progress', None), ('of', None), ('the', None), ('humankind', None), ('as', None), ('I', None), ('progress', None)]\n",
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'WPS'), ('any', None), ('irregularities', None), ('took', None), ('place', None), ('.', None)]\n"
     ]
    }
   ],
   "source": [
    "# funciona fatal :-(\n",
    "print(bigramTagger.tag(oracion2))\n",
    "print(trigramTagger.tag(oracion2))\n",
    "\n",
    "#aquí hago trampas, le pido que analice una oración que ya ha visto durante el entrenamiento\n",
    "print(bigramTagger.tag(['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \n",
    "\"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ve en los ejemplos, los resultados son desastrosos. La mayoría de los tokens se quedan sin etiqueta y se muestran como `None`.\n",
    "\n",
    "Si los evaluamos con nuestra colección de test, vemos que apenas superan el 10% de precisión. Peores resultados que nuestro `DefaultTagger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10196352038273697\n",
      "0.0626931127279976\n"
     ]
    }
   ],
   "source": [
    "print(bigramTagger.evaluate(corpusTest))\n",
    "print(trigramTagger.evaluate(corpusTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué ocurre esto? La intuición no nos engaña, y es verdad que si calculamos distribuciones de frecuencia condicionales teniendo en cuenta secuencias de palabras más largas, nuestros datos serán más finos. Sin embargo, cuando consideramos secuencias de tokens más largos nos arriesgamos a que dichas secuencias no aparezcan como tales en el corpus de entrenamiento. \n",
    "\n",
    "En el ejemplo de `oracion2`, nuestro `bigramTagger` es incapaz de etiquetar la palabra *progress* porque no ha encontrado en el corpus de entrenamiento ni el bigrama (**The, progress**) ni (**I, progress**). Obviamente, nuestro `trigramTagger` tampoco ha encontrado los trigramas (**`INICIO_DE_ORACIÓN`, The, progress**) o (**as, I, progress**). Si esas secuencias no aparecen en el corpus de entrenamiento, no hay nada que aprender. \n",
    "\n",
    "\n",
    "\n",
    "### Combinamos etiquetadores\n",
    "\n",
    "En estos casos, la solución más satisfactoria consiste en combinar de manera incremental la potencia de todos nuestros etiquetadores. Vamos a crear nuevos taggers que utilicen otros como respaldo. \n",
    "\n",
    "Utilizaremos un tagger de trigramas que, cuando no tenga respuesta para etiquetar un determinado token, utilizará como respaldo el tagger de bigramas. A su vez, el tagger de bigramas tirará del de unigramas cuando no tenga respuesta. Por último, el de unigramas utilizará como respaldo el tagger de expresiones regulares que definimos antes. De esta manera aumentamos la precisión hasta casi el 87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8656433768563739\n"
     ]
    }
   ],
   "source": [
    "unigramTagger = nltk.UnigramTagger(corpusEntrenamiento, backoff=regexTagger)\n",
    "bigramTagger = nltk.BigramTagger(corpusEntrenamiento, backoff=unigramTagger)\n",
    "trigramTagger = nltk.TrigramTagger(corpusEntrenamiento, backoff=bigramTagger)\n",
    "print(trigramTagger.evaluate(corpusTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'BEZ'), ('the', 'AT'), ('lost', 'VBD'), ('dog', 'NN'), ('I', 'PPSS'), ('found', 'VBD'), ('at', 'IN'), ('the', 'AT'), ('park', 'NN')]\n",
      "[('The', 'AT'), ('progress', 'NN'), ('of', 'IN'), ('the', 'AT'), ('humankind', 'NN'), ('as', 'CS'), ('I', 'PPSS'), ('progress', 'NN')]\n",
      "[('Green', 'JJ-TL'), ('colorless', 'NNS'), ('ideas', 'NNS'), ('sleep', 'NN'), ('furiously', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "print(trigramTagger.tag(oracion1))\n",
    "print(trigramTagger.tag(oracion2))\n",
    "print(trigramTagger.tag(oracion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio en clase\n",
    "\n",
    "Vamos a mejorar nuestro etiquetador extendiendo el corpus de entrenamiento. En lugar de usar solo los textos de noticias, vamos a utilizar el corpus de Brown completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daniel', 'personally', 'led', 'the', 'fight', 'for', 'the', 'measure', ',', 'which', 'he', 'had', 'watered', 'down', 'considerably', 'since', 'its', 'rejection', 'by', 'two', 'previous', 'Legislatures', ',', 'in', 'a', 'public', 'hearing', 'before', 'the', 'House', 'Committee', 'on', 'Revenue', 'and', 'Taxation', '.']\n",
      "[('Daniel', 'NP'), ('personally', 'RB'), ('led', 'VBD'), ('the', 'AT'), ('fight', 'NN'), ('for', 'IN'), ('the', 'AT'), ('measure', 'NN'), (',', ','), ('which', 'WDT'), ('he', 'PPS'), ('had', 'HVD'), ('watered', 'VBN'), ('down', 'RP'), ('considerably', 'RB'), ('since', 'IN'), ('its', 'PP$'), ('rejection', 'NN'), ('by', 'IN'), ('two', 'CD'), ('previous', 'JJ'), ('Legislatures', 'NNS-TL'), (',', ','), ('in', 'IN'), ('a', 'AT'), ('public', 'JJ'), ('hearing', 'NN'), ('before', 'IN'), ('the', 'AT'), ('House', 'NN-TL'), ('Committee', 'NN-TL'), ('on', 'IN-TL'), ('Revenue', 'NN-TL'), ('and', 'CC-TL'), ('Taxation', 'NN-TL'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "oracionNoAnotadas = brown.sents()\n",
    "oracionAnotadas = brown.tagged_sents() # esta es la colección que usaremos para el training\n",
    "\n",
    "# como ves, son el mismo corpus\n",
    "print(oracionNoAnotadas[100])\n",
    "print(oracionAnotadas[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El corpus tiene 57340 oraciones\n",
      "Vamos a usar las primeras 43005 oraciones para entrenar y las 14335 restantes como test.\n",
      "\n",
      "\n",
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n",
      "[('When', 'WRB'), ('the', 'AT'), ('Plymouth', 'NP'), ('neared', 'VBD'), (',', ','), ('it', 'PPS'), ('veered', 'VBD'), ('toward', 'IN'), ('him', 'PPO'), ('and', 'CC'), ('seemed', 'VBD'), ('about', 'RB'), ('to', 'TO'), ('run', 'VB'), ('him', 'PPO'), ('down', 'RP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "totalOraciones = len(oracionNoAnotadas)\n",
    "print(\"El corpus tiene\", totalOraciones, \"oraciones\")\n",
    "\n",
    "# en este caso, vamos a utilizar para entrenar un 75% de los datos\n",
    "# y como test el 25% restante\n",
    "limite = int(totalOraciones * 0.75) # ojo, esto tiene que ser un entero\n",
    "print(\"Vamos a usar las primeras\", limite, \"oraciones para entrenar y las\", totalOraciones-limite, \"restantes como test.\\n\\n\")\n",
    "\n",
    "# creo el corpus de entrenamiento\n",
    "corpusEntrenamiento = oracionAnotadas[:limite]\n",
    "corpusTest = oracionAnotadas[limite:]\n",
    "\n",
    "# como ves, son corpus diferentes\n",
    "print(corpusEntrenamiento[0])\n",
    "print(corpusTest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fíjate cómo importo ahora las clases para crear etiquetadores basados en ngramas y cómo los uso después\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "# creamos de manera incremental tres etiquetadore basados en ngramas, \n",
    "# usando como respaldp etiquetadores más sencillos\n",
    "unigramTagger = UnigramTagger(corpusEntrenamiento, backoff=regexTagger)\n",
    "bigramTagger = BigramTagger(corpusEntrenamiento, backoff=unigramTagger)\n",
    "trigramTagger = TrigramTagger(corpusEntrenamiento, backoff=bigramTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'BEZ'), ('the', 'AT'), ('lost', 'VBN'), ('dog', 'NN'), ('I', 'PPSS'), ('found', 'VBD'), ('at', 'IN'), ('the', 'AT'), ('park', 'NN')]\n",
      "[('The', 'AT'), ('progress', 'NN'), ('of', 'IN'), ('the', 'AT'), ('humankind', 'NN'), ('as', 'CS'), ('I', 'PPSS'), ('progress', 'NN')]\n",
      "[('Green', 'JJ'), ('colorless', 'JJ'), ('ideas', 'NNS'), ('sleep', 'NN'), ('furiously', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "# qué tal analiza oraciones\n",
    "print(trigramTagger.tag(oracion1))\n",
    "print(trigramTagger.tag(oracion2))\n",
    "print(trigramTagger.tag(oracion3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.910920747900888\n"
     ]
    }
   ],
   "source": [
    "# vamos a ver qué precisión tiene, analizando el corpus de test\n",
    "print(trigramTagger.evaluate(corpusTest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
